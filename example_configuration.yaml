# TODO physical scale of the data
# TODO discuss the depenendencies more closely
# TODO discuss the training, description of the training process, training data 

name: UNet2dExample
description: A 2d U-Net pretrained on broad nucleus dataset.
format_version: 0.1.0
language: python
framework: pytorch
# we allow for multiple citations. Each citation contains TEXT, DOI and URL. One of DOI or URL needs to be given.
cite:
    - {text: "Ronneberger, Olaf et al. U-net: Convolutional networks for biomedical image segmentation. MICCAI 2015.", doi: https://doi.org/10.1007/978-3-319-24574-4_28}
# TODO authors = github handles optional
authors:
    - Constantin Pape
    - Fynn Beutenmueller
documentation: ./unet2d.md
tags: [unet2d, pytorch, nucleus-segmentation]
# optional:
thumbnail: ./my_thumbnail.png
test_input: ./my_test_image.png
test_output: ./my_test_output.png

model:
    # how would this look for a FIJI project?
    # how to specify entry point
    # ('native entry point')
    definition:  # native entry point
        source: ./unet2d.py:UNet2d
        kwargs: {input_channels: 1, output_channels: 1}
    input: # needs to become ordered dict (same for output) or list of dicts should contain names to 
        # discussion about NCHWD versus bxyzt this also has implications on the location of the origin and the 
        axes: bcyx #btczyx
        data_type: float32
        data_range: [-inf, inf]
        shape:
            min: [1, 1, 32, 32]
            step: [null, 0, 32, 32]
            # exact can also be list
            # exact: [null, 1, 256, 256]
    output:
        axes: bcyx
        data_type: float32
        data_range: [0, 1]
        shape:
            scale: [1, 1, 1, 1]
            offset: [0, 0, 0, 0]
            # exact: [...]
            # halo tells you what to crop from the output image
            halo: [0, 0, 32, 32]

# discussion: do we support a single or multiple weights?
# example kipoi: ginger templating
# list for ensembles?
# FOR NOW: One model one weight file
prediction:
    preprocess:
        - {name: core.transforms.NormalizeZeroMeanUnitVariance, kwargs: {}}
    weights:
        source: 10.5281/zenodo.3446812
        hash: {md5: c16cb3ba3cb9d257550fd19067ecfb91}
    postprocess: []
    # enable different ways of specifying the dependencies.
    # this would hold all training dependencies, e.g. as a frozen conda environment
    # or as a pom.xml
    dependencies: # this is a file to the dependencies
        conda:./environment.yaml
    # bioimageio_normalize: 0.1
    # optional reference data

training:
    preprocess:
        - {name: core.transforms.NormalizeZeroMeanUnitVariance, kwargs: {}}
        # - {name: bioimageio_normalize.NormalizeZeroMeanUnitVariance, kwargs: {}}
    loss:
        # - {name: torch.nn.Sigmoid}
        - {name: core.transforms.Sigmoid}
        - {name: torch.nn.BCELoss, kwargs: {reduction: mean}}
    optimizer:
        name: torch.optim.Adam
        kwargs: {lr: 0.002}
    validation:
        - {}
    input:
        shape: [4, 1, 512, 512]
    target:
        shape: [4, 1, 512, 512]
        axes: bcyx
    # entry_point: ./unet2d.py:train
    # more hyperparameters
    # initialization: {name: FromWeights, kwargs: {uri: ...}}
    # initialization: {name: He}
    train_on:
        # todo: sampling
        dataset: something  # can take a list of source
        n_iterations: 1000
        # n_epochs: 10
    # enable different ways of specifying the dependencies.
    # this would hold all training dependencies, e.g. as a frozen conda environment
    # or as a pom.xml
    dependencies: # this is a file to the dependencies
        conda:./environment.yaml
